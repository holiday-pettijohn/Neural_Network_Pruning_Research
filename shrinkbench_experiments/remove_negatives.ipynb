{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrinkbench.experiment import PruningExperiment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DATAPATH` environment variable is used to tell the framework where to look for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to change the path\n",
    "data_path = '/home/zache1/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DATAPATH'] = data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "torchvision.datasets.MNIST(root=data_path + '/MNIST',train=False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run experiments for our MNIST network for logarithmically spaced compression ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out how to implement my own strategy\n",
    "from shrinkbench.pruning import (VisionPruning)\n",
    "import shrinkbench.strategies\n",
    "from shrinkbench.strategies import utils\n",
    "\n",
    "class my_strategy(VisionPruning):\n",
    "\n",
    "    def model_masks(self):\n",
    "        importances = utils.map_importances(lambda x : np.maximum(0, x), self.params())\n",
    "        flat_importances = utils.flatten_importances(importances)\n",
    "        threshold = utils.fraction_threshold(flat_importances, self.fraction)\n",
    "        masks = utils.importance_masks(importances, threshold)\n",
    "        return masks\n",
    "\n",
    "# need to do this so that shrinkbench can get my strategy\n",
    "setattr(shrinkbench.strategies, 'my_strategy', my_strategy)\n",
    "\n",
    "for s in ['my_strategy', 'GlobalMagWeight', 'LayerMagWeight']:\n",
    "    for c in [1,2,4, 8, 16, 32, 64]:\n",
    "        exp = PruningExperiment(dataset='MNIST', \n",
    "                                model='MnistNet',\n",
    "                                strategy=s,\n",
    "                                compression=c,\n",
    "                                train_kwargs={'epochs':10},\n",
    "                                pretrained=False)\n",
    "        exp.run()\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then collect output from experiment folders and plot the diferent metrics easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrinkbench.plot import df_from_results, plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_results('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the provided functions, it is easy to generate plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df, 'compression', 'pre_acc5', markers='strategy', line='--', colors='strategy', suffix=' - pre')\n",
    "plot_df(df, 'compression', 'post_acc5', markers='strategy', fig=False, colors='strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the theoretical speedup and see that layerwise provides larger FLOPS speedups because of the even pruning of the conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df, 'speedup', 'post_acc5', colors='strategy', markers='strategy')\n",
    "\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(0.985,0.99)\n",
    "\n",
    "plt.xticks(2**np.arange(7))\n",
    "plt.gca().set_xticklabels(map(str, 2**np.arange(7)))\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily check if the compression is matching our expectation by looking at the relative error. As expected, random pruning does worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compression_err'] = (df['real_compression'] - df['compression'])/df['compression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df, 'compression', 'compression_err', colors='strategy', markers='strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa525ecb06e7696e7c50de027d7dcf5ea4f2da2d32b67126bfed00f9e31d8fd3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}