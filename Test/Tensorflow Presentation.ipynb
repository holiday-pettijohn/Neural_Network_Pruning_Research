{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48c7628",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3886104b",
   "metadata": {},
   "source": [
    "**Tensorflow** is an end-to-end open source platform for machine learning<br>\n",
    "To install tensorflow, open the anaconda prompt, activate the correct environment, then run `conda install tensorflow`\n",
    "\n",
    "**Keras** is a deep learning API written in Python, running on top of the machine learning platform TensorFlow.\n",
    "\n",
    "**NumPy** is an open source project aiming to enable numerical computing with Python.\n",
    "\n",
    "**Matplotlib** is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "\n",
    "**pathlib** is a python module used for file system paths\n",
    "\n",
    "**tensorflow_datasets** is a collection of datasets ready to use\n",
    "\n",
    "**pandas** is a library that provides easy-to-use data structures and data analysis tools for the Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdffbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7f734",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ca09e",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"flower_photos\")\n",
    "\n",
    "if not data_dir.is_dir():\n",
    "    dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "    data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "print(data_dir.resolve())\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "validation_split = 0.2\n",
    "seed = 404 # Where did it go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341396cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a tf.data.Dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=data_dir, # no default value - the directory containing the data\n",
    "    labels='inferred', # default value - uses names of folders containing the images\n",
    "    label_mode='int', # default value - other options are 'categorical' and 'binary'\n",
    "    class_names=None, # default value - changes the order of the classes when specified\n",
    "    color_mode='rgb', # default value - changes the amount of channels used from images ('grayscale', 'rgb', or 'rgba')\n",
    "    batch_size=batch_size, # default is 32 - size of the batches of data\n",
    "    image_size=(img_height, img_width), # default is 256, 256 - resize all images to same dimensions\n",
    "    shuffle=True, # default value - shuffles data, otherwise keeps data in alphanumeric order\n",
    "    seed=seed, # default is None - the shuffle seed\n",
    "    validation_split=validation_split, # default is None - what percentage of the data is used for checking data\n",
    "    subset=\"training\", # default is None - when splitting data into training and validating, specify which type\n",
    "    interpolation='bilinear', # default value - The method used to resize images. Also supports \"nearest\", \"bicubic\", \"area\", \"lanczos3\", \"lanczos5\", \"gaussian\", \"mitchellcubic\".\n",
    "    follow_links=False, # default value - Whether it visits subdirectories pointed to by symlinks (aka Symbolic Links).\n",
    "    crop_to_aspect_ratio=False # default value - When true, resizes the images without aspect ratio distortion\n",
    ")\n",
    "# see https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
    "# for more details on the following function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ef214",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    seed=seed,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f7db6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa686dc",
   "metadata": {},
   "source": [
    "### The following cell of code is for performance\n",
    "\n",
    "Straight from the [tutorial](https://www.tensorflow.org/tutorials/load_data/images) because I have no idea how I would better explain it myself:\n",
    "\n",
    ">Let's make sure to use buffered prefetching so you can yield data from disk >without having I/O become blocking. These are two important methods you should use when loading data:<br>\n",
    ">* Dataset.cache keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.<br>\n",
    ">* Dataset.prefetch overlaps data preprocessing and model execution while training.\n",
    ">\n",
    ">Interested readers can learn more about both methods, as well as how to cache data to disk in the Prefetching section of the [Better performance with the tf.data API](https://github.com/tensorflow/docs/blob/1054aa3c4bc8379799fe84b32f5b8ef31ddfa61f/site/en/guide/data_performance.ipynb) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd529b",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06787fd0",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0314a6",
   "metadata": {},
   "source": [
    "Want a list of types of layers?<br>\n",
    "Or maybe a list of different activation functions?<br>\n",
    "See https://keras.io/api/layers/ or https://www.tensorflow.org/api_docs/python/tf/keras/layers for the official documentation on these cool concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b9d5c",
   "metadata": {},
   "source": [
    "#### What is data augmentation?\n",
    "Data augmentation is\n",
    ">a technique to increase the diversity of your training set by applying random (but realistic) transformations, such as image rotation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d317e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\n",
    "                            \"horizontal\",\n",
    "                            input_shape=(img_height, img_width, 3),\n",
    "                            seed=42\n",
    "                         ),\n",
    "        tf.keras.layers.RandomRotation(0.1, seed=314159265),\n",
    "        tf.keras.layers.RandomZoom(0.1, seed=271828)\n",
    "    ]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset:\n",
    "    plt.imshow(images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(data_augmentation(images[0].numpy().astype(\"uint8\") / 255.0))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1.0/255.0, offset=0), # standardize the values to 0-1\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'), # use the string name for the activation\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=tf.nn.relu), # or use the function for the activation\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb3b3f",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "The `compile` function conigures the model for training<br>\n",
    "Click [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) for different optimizer algorithms supported by tensorflow<br>\n",
    "Click [here](https://www.tensorflow.org/api_docs/python/tf/keras/losses) for different loss functions supported by tensorflow<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf816063",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "Click [here](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) for how to setup your own training loop from scratch<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "print(type(train_dataset))\n",
    "history = model.fit(\n",
    "    x=train_dataset, # the input data\n",
    "    y=None, # the target data. Is not specified here since the input is a dataset\n",
    "    batch_size=None, # The batch size. Is not specified here since the input is a dataset\n",
    "    epochs=epochs, # the number of iterations over the entire data provided (https://youtu.be/eJ9-d9jheMI)\n",
    "    verbose='auto', # default value - what stuff to print\n",
    "    validation_data=validation_dataset,\n",
    "    shuffle=True, # default value - whether to shuffle the dataset before each value\n",
    "    class_weight=None, # default value - used for weighting the loss function during training\n",
    "    sample_weight=None, # default value - also used for weighting the loss function\n",
    "    initial_epoch=0, # default value - the epoch to start training (used for resuming from previous training)\n",
    "    # steps_per_epoch=None, # default value - The number of steps before declaring one epoch finished and starting the next epoch. However, steps_per_epoch=None is not supported\n",
    "    validation_steps=None, # default value - the total number of steps to draw before stopping when performing validation at the end of every epoch\n",
    "    validation_batch_size=None, # Number of samples per validation batch\n",
    "    validation_freq=1, # default value - specifies how many training epochs to run  before a new validation run is performed\n",
    "    max_queue_size=10, # default value - maximum size for the generator queue\n",
    "    workers=1, # default value - maximum number of processses to spin up when using process-based threading\n",
    "    use_multiprocessing=False # default value - If true, use process-based threading\n",
    ")\n",
    "# see https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit for more details on this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf475b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19774858",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    sunflower_path, target_size=(img_height, img_width)\n",
    ")\n",
    "plt.imshow(img)\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5602b00",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "Click [here](https://www.tensorflow.org/tutorials/keras/save_and_load) for more information on saving models, including saving models after a training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models = pathlib.Path('saved_models')\n",
    "if not saved_models.is_dir():\n",
    "    saved_models.mkdir()\n",
    "\n",
    "model.save('saved_models\\my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92432723",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_models\\my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c89c3a",
   "metadata": {},
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29777231",
   "metadata": {},
   "source": [
    "Using `pandas` to read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_file_path = pathlib.Path(\"abalone_train.csv\")\n",
    "if abalone_file_path.is_file():    \n",
    "    abalone_train = pd.read_csv(\n",
    "        \"abalone_train.csv\",\n",
    "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "    )\n",
    "else:\n",
    "    abalone_train = pd.read_csv(\n",
    "        \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "    )    \n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acafd537",
   "metadata": {},
   "source": [
    "We will try to predict the age based on the rest of the data.<br>\n",
    "To do so, we will create a features remove the `'Age'` category from the pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b175bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')\n",
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87591629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())\n",
    "\n",
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e58b04",
   "metadata": {},
   "source": [
    "For more information on loading CSV files (including files that contain different data types and not just numbers) click [here](https://www.tensorflow.org/tutorials/load_data/csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfe9f2",
   "metadata": {},
   "source": [
    "### Loading Text\n",
    "Click [here](https://www.tensorflow.org/tutorials/load_data/text) to see the basics of text loading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f5194",
   "metadata": {},
   "source": [
    "# Further Studying\n",
    "#### Want to learn more about tensorflow? No better way to learn than the [official tutorials](https://www.tensorflow.org/tutorials).\n",
    "*Be sure to look on the left-hand side or the hambuger menu dropdown for all of this great information and more* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4984419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
